{
  "hash": "214c7b914ea3bd4c1be4963487a8d833",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Mind reading becomes more accurate in recent study by Cambridge scientists\" \ndate: 2026-01-29\ncategories:\n  - \"Featured\"\ndescription:  |\n   *Lead scientist Weihao Xia worked with Cengiz Oztireli on the VINDEX (“VIsual experts for multimodal Neural DEcoding eXploration”) study to further understand our brains using scan data and AI.*\n\nimage: \"Stephanie.jpg\" \ninfo:\n  author: \"Stephanie Dickinson\"\n  pic: Stephanie.jpg\n  bio: Stephanie Dickinson is the current Sustainability/Green Champion for the UCL Department of Statistical Science.\n  website:\n    \n---\n\n\n\nUnderstanding preciseness in AI’s verbal interpretation of images could enable people with disabilities to use machines controlled by their thoughts. In a study titled “Exploring The Visual Feature Space for Multimodal Neural Decoding” into brain activity, images from fMRI (functional Magnetic Resonance Imaging) scans were interpreted by machines. Simply, this means the images were interpreted from within the human brain. \n\nWhat is new about the VINDEX study? This type of research has been around for a couple of years but what has changed is the level of detail in descriptions that can now be written by AI when fed brain scan imagery. It “aligned different image encoders” [a type of AI tool] to do this. This type of detail might be “the colour or the style of the clothes” in an image of clothing. So, rather than just a basic description, “it will give the objects and its attributes, and also the relationships among the different objects.” \n\nThe VINDEX study joins a larger body of work by many people in the fusion of mind and machine, “in the future [...] we can think, or we can paint or we can manipulate some devices by just imagining” Weihao says. “Elon Musk, his company Neuralink, [are] actually trying to make the visually impaired person to see again.”\n\n “There are some other guys trying to help people for example who cannot speak, and there are devices to decode their language and output in the screen.” Incredibly, it is even possible use thoughts to make a machine cook. \n\nHe explains why they used fMRI imagery: “it actually captured the brain oxygen level, so it is more like the whole brain.” This is different to EEG (Electroencephalography) which he describes as “on the surface” and “not very precise.” How Weihao’s study worked was by capturing images of the “very precise changes in the brain when the subject views these images.” \n\nThey had to train the AI to understand images, using image encoders. These had to learn strategically in different styles, one of which is called constructive learning. He describes some of the process: “we have an image for like this cat, and we also have some like textual descriptions [...] the algorithms will try to learn, “oh this! These things are similar.”” Weihao explains that the familiar AI tool called a Large Language Model will try to “force a response,” and will “produce counter-facts.” Avoiding this scenario and producing more accurate captions is an important focus of the study. \n\nMind reading by machine seems like science fiction, and Weihao has ideas about where this research might be headed: “Currently we use language to communicate with each other. I believe in the future probably we can just... we do not need to talk.” He philosophises further: “Everything that we describe in scientific fiction will definitely come true anyway, it’s just that it takes some time.” \n\nLooking into people’s minds clearly has ethical implications, so what are the concerns? “The most basic one is we do not want to hurt people that get involved in this research.” He goes on to explain that preventing developments is important for “some area that will hurt some people or the whole human.” He asks, “if we can read some other guy’s brain at any time, what is the privacy?” \n\nInterviewee: [Dr Weihao Xia](mailto:wx258@cam.ac.uk), University of Cambridge CORE Lab. Weihao Xia completed his PhD in the Department of Statistical Science, UCL.\n\n\n<br><br>\n\n:::: {.author-block}\n::: {style=\"float: left;margin-right: 20px;margin-top: -0px;margin-bottom:0px; object-fit:contain\"}\n![]({{< meta info.pic >}}){width=\"60px\" height=\"60px\" height=\"auto\" width=\"auto\\9\"}\n:::\n# **{{< meta info.author >}}**    \n## {{< meta info.bio >}}\n\n\n\n\n\n::::\n\n\n\n<br>\n\n\n<!--\nThis files first derives the relative path to the folder under which the page to share on selected social media is stored. \nThen it creates a series of sharing buttons --- currently implemented:\n- Twitter\n- Email\n- LinkedIn\n- Whatsapp\nOthers are fairly easy to create --- only need the fa icon of the relevant media + the combination of text that would be required\nto automatically share in on that platform\n-->\n\n\n::: {.cell}\n\n:::\n\n\n<br>\n<center>\n<!-- This uses a trick and an external widget to share on any of the federated servers on Mastodon\n   see: https://shkspr.mobi/blog/2022/06/create-a-share-to-mastodon-button-for-wordpress/\n-->\n\n[{{< fa brands mastodon size=lg title=\"Share on Mastodon\" color=\"#383838\" >}}](https://toot.kytta.dev/?text=Mind reading becomes more accurate in recent study by Cambridge scientists https://sample-space.org/posts/features/2026-01-29-Mind-reading-becomes-more-accurate-in-recent-study-by-Cambridge-scientists){target=\"_blank\" onclick=\"window.open(this.href,'targetWindow','toolbar=no,location=no,status=no,menubar=no,scrollbars=yes,resizable=yes,width=400px,height=600px'); return false;\"} &nbsp;\n[{{< fa brands twitter size=lg title=\"Share on Twitter\" color=\"#383838\" >}}](https://twitter.com/intent/tweet?url=https://sample-space.org/posts/features/2026-01-29-Mind-reading-becomes-more-accurate-in-recent-study-by-Cambridge-scientists/&text=Mind reading becomes more accurate in recent study by Cambridge scientists){target=\"_blank\"} &nbsp;\n[{{< fa envelope size=lg title=\"Share by email\" color=\"#383838\">}}](mailto:?subject=Mind reading becomes more accurate in recent study by Cambridge scientists&body=https://sample-space.org/posts/features/2026-01-29-Mind-reading-becomes-more-accurate-in-recent-study-by-Cambridge-scientists){target=\"_blank\"} &nbsp;\n[{{< fa brands linkedin size=lg title=\"Share on LinkedIn\" color=\"#383838\" >}}](https://www.linkedin.com/shareArticle?url=https://sample-space.org/posts/features/2026-01-29-Mind-reading-becomes-more-accurate-in-recent-study-by-Cambridge-scientists/&title=Mind reading becomes more accurate in recent study by Cambridge scientists){target=\"_blank\"} &nbsp;\n[{{< fa brands whatsapp size=lg title=\"Share on Whatsapp\" color=\"#383838\" >}}](https://web.whatsapp.com/send?text=Mind reading becomes more accurate in recent study by Cambridge scientistshttps://sample-space.org/posts/features/2026-01-29-Mind-reading-becomes-more-accurate-in-recent-study-by-Cambridge-scientists/){target=\"_blank\"} &nbsp;\n[{{< fa brands reddit size=lg title=\"Share on Reddit\" color=\"#383838\" >}}](https://reddit.com/submit?url=https://sample-space.org/posts/features/2026-01-29-Mind-reading-becomes-more-accurate-in-recent-study-by-Cambridge-scientists/&title=Mind reading becomes more accurate in recent study by Cambridge scientists){target=\"_blank\"}\n</center>\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}